seed_everything: 19

trainer:

  default_root_dir: ./results/image_disease_classification_19
  accelerator: cuda
  devices: 1
  log_every_n_steps: 1
  max_epochs: 100


  callbacks:
  - class_path: lightning.pytorch.callbacks.RichProgressBar
  - class_path: lightning.pytorch.callbacks.EarlyStopping
    init_args:
        monitor: 'val_loss'
        patience: 4
        mode: 'min'  # or 'max' depending on your metric
  - class_path: lightning.pytorch.callbacks.ModelCheckpoint
    init_args:
        monitor: 'val_loss'
        mode: 'min'  # or 'max' depending on your metric
        save_top_k: 20  # save only the best checkpoint
        dirpath: './results/image_disease_classification_19/checkpoints/'
        filename: 'best_val_loss-{epoch:02d}-{val_loss:.4f}'

# This configuration uses PyTorch's ConcatDataset to combine two datasets (e.g., MIMIC and CheXpert)
# for each of the train, validation, and test splits. Each dataset is defined separately with its own
# CSV metadata (dataframe_path), image root directory (path_image), and transformation pipeline.
# The combined datasets are treated as a single dataset during training, allowing unified batching
# and evaluation across both sources.

data:

  train_dataset:
    class_path: torch.utils.data.ConcatDataset
    init_args:
      datasets:
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/train_mimic.csv
            path_image: /datasets/mimic-cxr
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.RandomHorizontalFlip
                  - class_path: torchvision.transforms.RandomRotation
                    init_args:
                      degrees: 15
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/train_chexpert.csv
            path_image: /datasets/chexpert
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.RandomHorizontalFlip
                  - class_path: torchvision.transforms.RandomRotation
                    init_args:
                      degrees: 15
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]

  val_dataset:
    class_path: torch.utils.data.ConcatDataset
    init_args:
      datasets:
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/val_mimic.csv
            path_image: /datasets/mimic-cxr
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/val_chexpert.csv
            path_image: /datasets/chexpert
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]

  test_dataset:
    class_path: torch.utils.data.ConcatDataset
    init_args:
      datasets:
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/test_mimic.csv
            path_image: /datasets/mimic-cxr
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]
        - class_path: data.image.dataset_class.ImageDataset
          init_args:
            dataframe_path: ./datasets/test_chexpert.csv
            path_image: /datasets/chexpert
            transform:
              class_path: torchvision.transforms.Compose
              init_args:
                transforms:
                  - class_path: torchvision.transforms.Resize
                    init_args:
                      size: [256, 256]
                  - class_path: torchvision.transforms.CenterCrop
                    init_args:
                      size: 256
                  - class_path: torchvision.transforms.ToTensor
                  - class_path: torchvision.transforms.Normalize
                    init_args:
                      mean: [0.485, 0.456, 0.406]
                      std: [0.229, 0.224, 0.225]

  batch_size: 48
  num_workers: 25
  prediction_on: 'test'  # Options: "train", "val", "test"


model: # models.module.CLS
  model:
    class_path: models.image.models.DensNetWithHead
    init_args:
      hidden_layer_sizes: [768,256] # chanege this to match your model's architecture
      dropout_rate: 0.0
      num_classes: 14
  criterion: # torch.nn.BCEWithLogitsLoss
    class_path: torch.nn.BCEWithLogitsLoss
  prediction_on: 'test'  # Options: "train", "val", "test"
  save_probabilities_path: ./results/image_disease_classification_19/probabilities